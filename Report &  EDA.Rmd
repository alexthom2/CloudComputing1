---
title: "Report"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction 

This project looks at a sample of data form the terapixel images cloude system for the newcastle urban oberservatory. The system is set up to be scalable depening on user demands and outpuits a 3d visualisation of newcastle city scentre. This project looks at the performance of the virtual machines and looks at developing a set of visualisations that can be regularly run to understand the current perofrmance of the system. Currently there is no set regime of perofmrance monitoring of the cloud based uystem and in order to improve user experiences by ensuring the system is fast and responsive for every user a set of visualisations will be developed 



```{r}


## packages used 
library(tidyverse)

library(lubridate)

```



```{r}

# data read from the 
setwd("~/Data Science Masters/cloudcomputing/data")

gpu <- read_csv("gpu.csv")

appcheck <- read_csv("application-checkpoints.csv")

task <- read_csv("task-x-y.csv")



```

```{r}


# reviewing the structure of the 3 data frames 

str(gpu)



str(appcheck)


str(task)






```




The Data is made up of 3 data frames. Ther first the appacheck which is the action of the virtual machine at that precise time. GPU which is static data for the GPU and task identifies which precise pixel the virtual machine was rendering at the time of the task. The first thing to look at is how the individual takss are broken down 


```{r}





appcheck %>% group_by(jobId) %>%
                              summarise(n = n())




 appcheck %>% group_by(taskId) %>%
                              summarise(n = n())



appcheck %>% group_by(hostname) %>%
                              summarise(n = n())


```


Jobid seems to not be too informative with only 3 levels. Taskid looks to be related to the generation of a pixel and looks to be the area that will be investigated. hostname is each GPU which we will be monitoring the performance of. 






```{r}


host_us <- appcheck %>%  filter(eventName == "TotalRender")  %>%
                            arrange(timestamp) %>%
                             group_by(hostname, taskId) %>%
                            mutate(rown = 1:n()) %>%
                              filter(rown == 1) 



host_us_end <- appcheck %>%  filter(eventName == "TotalRender") %>%
                                 arrange(timestamp) %>%
                            group_by(hostname, taskId) %>%
                               mutate(rown = 1:n()) %>%
                              slice_max(rown) %>%
                              select(timestamp, hostname, taskId)


colnames(host_us_end)[1] <- "timeend"


data <- host_us %>% left_join(host_us_end, by = c("hostname", "taskId")) %>%
                            mutate(duration = timeend - timestamp)
                             


ggplot(data, aes(x = duration)) + geom_histogram()







```

There is a range of task runtimes from as low as 23 seconds to as high as 93 seconds with most full tasks taking around 40 seconds. This is the area to investigate further to understand the cause of the difference 





```